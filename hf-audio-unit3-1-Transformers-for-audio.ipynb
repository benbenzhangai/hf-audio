{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41d975eb-f1ca-4948-b35c-a62c33f691bd",
   "metadata": {},
   "source": [
    "## Model inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b00a1d-fbe3-48f6-a167-abc544ac927c",
   "metadata": {},
   "source": [
    "- Text input (Text-to-speech, TTS)\n",
    "- Waveform (ASR task): examples include Wav2Vec2 and HuBERT\n",
    "   - First do the input normalization\n",
    "   - then a feature encoder -- a small CNN\n",
    "   - Each of the convolutional layers in this network processes the input        sequence, subsampling the audio to reduce the sequence length, until        the final convolutional layer outputs a 512-dimensional vector with         the embedding for each 25 ms of audio.\n",
    "- Spectrogram input\n",
    "   - Downside of the raw waveform input is they tend to have logn sequences. Spectrogram can be more compressed.\n",
    "   - Whisper converts the waveform into log-mel spectrogram. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071e18b-3e62-4fb2-a149-97ad8d3a1b8b",
   "metadata": {},
   "source": [
    "## Model outputs\n",
    "\n",
    "- Text output: a signle linear layer of language model head.\n",
    "- Spectrogram output: generate spectrogram and then use additional NN called vocoder to convert to waveform. The audio models generally only produce the amplitude info not the phase, that's what a vocoder does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2fcdd-a3fb-4ee8-8795-8eac3deac130",
   "metadata": {},
   "source": [
    "## CTC architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8739195-9993-41da-b2e9-24e9d50b23e4",
   "metadata": {},
   "source": [
    "Type: Encoder-only transformer models for ASR.\n",
    "\n",
    "Examples: Wav2Vec2, HuBERT and M-CTC-T.\n",
    "\n",
    "Encoder with a character classification head.\n",
    "\n",
    "Good for small vocab.\n",
    "\n",
    "Timing is not available in data, so alignment between text and speech doesn't exist. Blank token is a predicted token that serves as a hard boundary between groups of characters. It makes it possible to filter out the duplicate characters\n",
    "\n",
    "The output could only sound correct but the spelling has no guarantee."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772dfac1-802a-4c0f-b42a-36034a9d7277",
   "metadata": {},
   "source": [
    "## Audio classifications\n",
    "\n",
    "- Treat the spectrogram as an image and do ViT\n",
    "- Repurpose a transformer, such as CTC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d3b57-a9b3-4ba5-9bf2-00f0261dacce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
