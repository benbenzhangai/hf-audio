{
  "best_global_step": 565,
  "best_metric": 0.82,
  "best_model_checkpoint": "distilhubert-finetuned-gtzan/checkpoint-565",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 565,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04424778761061947,
      "grad_norm": 1.1449623107910156,
      "learning_rate": 1.7699115044247788e-06,
      "loss": 2.2861,
      "step": 5
    },
    {
      "epoch": 0.08849557522123894,
      "grad_norm": 1.6510204076766968,
      "learning_rate": 3.982300884955752e-06,
      "loss": 2.289,
      "step": 10
    },
    {
      "epoch": 0.13274336283185842,
      "grad_norm": 1.1722270250320435,
      "learning_rate": 6.194690265486726e-06,
      "loss": 2.2741,
      "step": 15
    },
    {
      "epoch": 0.17699115044247787,
      "grad_norm": 1.4926832914352417,
      "learning_rate": 8.407079646017701e-06,
      "loss": 2.2966,
      "step": 20
    },
    {
      "epoch": 0.22123893805309736,
      "grad_norm": 1.5397741794586182,
      "learning_rate": 1.0619469026548673e-05,
      "loss": 2.2728,
      "step": 25
    },
    {
      "epoch": 0.26548672566371684,
      "grad_norm": 1.9833863973617554,
      "learning_rate": 1.2831858407079647e-05,
      "loss": 2.2914,
      "step": 30
    },
    {
      "epoch": 0.30973451327433627,
      "grad_norm": 1.2983826398849487,
      "learning_rate": 1.504424778761062e-05,
      "loss": 2.2535,
      "step": 35
    },
    {
      "epoch": 0.35398230088495575,
      "grad_norm": 1.8112915754318237,
      "learning_rate": 1.7256637168141594e-05,
      "loss": 2.2537,
      "step": 40
    },
    {
      "epoch": 0.39823008849557523,
      "grad_norm": 1.2817487716674805,
      "learning_rate": 1.946902654867257e-05,
      "loss": 2.2791,
      "step": 45
    },
    {
      "epoch": 0.4424778761061947,
      "grad_norm": 1.5343743562698364,
      "learning_rate": 2.1681415929203542e-05,
      "loss": 2.2788,
      "step": 50
    },
    {
      "epoch": 0.48672566371681414,
      "grad_norm": 1.6184659004211426,
      "learning_rate": 2.3893805309734516e-05,
      "loss": 2.2208,
      "step": 55
    },
    {
      "epoch": 0.5309734513274337,
      "grad_norm": 1.6852747201919556,
      "learning_rate": 2.610619469026549e-05,
      "loss": 2.2329,
      "step": 60
    },
    {
      "epoch": 0.5752212389380531,
      "grad_norm": 1.7722140550613403,
      "learning_rate": 2.831858407079646e-05,
      "loss": 2.2293,
      "step": 65
    },
    {
      "epoch": 0.6194690265486725,
      "grad_norm": 1.9347562789916992,
      "learning_rate": 3.0530973451327434e-05,
      "loss": 2.1866,
      "step": 70
    },
    {
      "epoch": 0.6637168141592921,
      "grad_norm": 1.8920925855636597,
      "learning_rate": 3.274336283185841e-05,
      "loss": 2.149,
      "step": 75
    },
    {
      "epoch": 0.7079646017699115,
      "grad_norm": 2.1080193519592285,
      "learning_rate": 3.495575221238938e-05,
      "loss": 2.1437,
      "step": 80
    },
    {
      "epoch": 0.7522123893805309,
      "grad_norm": 3.8945271968841553,
      "learning_rate": 3.716814159292036e-05,
      "loss": 2.0822,
      "step": 85
    },
    {
      "epoch": 0.7964601769911505,
      "grad_norm": 1.6137644052505493,
      "learning_rate": 3.938053097345133e-05,
      "loss": 2.0252,
      "step": 90
    },
    {
      "epoch": 0.8407079646017699,
      "grad_norm": 4.367221355438232,
      "learning_rate": 4.15929203539823e-05,
      "loss": 2.069,
      "step": 95
    },
    {
      "epoch": 0.8849557522123894,
      "grad_norm": 3.666867256164551,
      "learning_rate": 4.380530973451328e-05,
      "loss": 2.0042,
      "step": 100
    },
    {
      "epoch": 0.9292035398230089,
      "grad_norm": 4.560084342956543,
      "learning_rate": 4.601769911504425e-05,
      "loss": 2.0425,
      "step": 105
    },
    {
      "epoch": 0.9734513274336283,
      "grad_norm": 4.888540744781494,
      "learning_rate": 4.823008849557522e-05,
      "loss": 1.9087,
      "step": 110
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.5,
      "eval_loss": 1.83154296875,
      "eval_runtime": 53.6867,
      "eval_samples_per_second": 1.863,
      "eval_steps_per_second": 0.242,
      "step": 113
    },
    {
      "epoch": 1.0176991150442478,
      "grad_norm": 6.26556921005249,
      "learning_rate": 4.9950835791543757e-05,
      "loss": 1.9371,
      "step": 115
    },
    {
      "epoch": 1.0619469026548674,
      "grad_norm": 3.2880985736846924,
      "learning_rate": 4.970501474926254e-05,
      "loss": 1.8339,
      "step": 120
    },
    {
      "epoch": 1.1061946902654867,
      "grad_norm": 4.991643905639648,
      "learning_rate": 4.9459193706981325e-05,
      "loss": 1.7344,
      "step": 125
    },
    {
      "epoch": 1.1504424778761062,
      "grad_norm": 4.315277099609375,
      "learning_rate": 4.92133726647001e-05,
      "loss": 1.6742,
      "step": 130
    },
    {
      "epoch": 1.1946902654867257,
      "grad_norm": 4.716861724853516,
      "learning_rate": 4.9016715830875125e-05,
      "loss": 1.6835,
      "step": 135
    },
    {
      "epoch": 1.238938053097345,
      "grad_norm": 5.1262102127075195,
      "learning_rate": 4.877089478859391e-05,
      "loss": 1.7226,
      "step": 140
    },
    {
      "epoch": 1.2831858407079646,
      "grad_norm": 3.7036373615264893,
      "learning_rate": 4.8525073746312687e-05,
      "loss": 1.6258,
      "step": 145
    },
    {
      "epoch": 1.3274336283185841,
      "grad_norm": 3.9151556491851807,
      "learning_rate": 4.827925270403147e-05,
      "loss": 1.6485,
      "step": 150
    },
    {
      "epoch": 1.3716814159292037,
      "grad_norm": 9.768646240234375,
      "learning_rate": 4.803343166175025e-05,
      "loss": 1.5928,
      "step": 155
    },
    {
      "epoch": 1.415929203539823,
      "grad_norm": 4.900234222412109,
      "learning_rate": 4.778761061946903e-05,
      "loss": 1.6012,
      "step": 160
    },
    {
      "epoch": 1.4601769911504425,
      "grad_norm": 4.511559009552002,
      "learning_rate": 4.754178957718781e-05,
      "loss": 1.475,
      "step": 165
    },
    {
      "epoch": 1.504424778761062,
      "grad_norm": 6.970420837402344,
      "learning_rate": 4.729596853490659e-05,
      "loss": 1.4712,
      "step": 170
    },
    {
      "epoch": 1.5486725663716814,
      "grad_norm": 8.933089256286621,
      "learning_rate": 4.705014749262537e-05,
      "loss": 1.476,
      "step": 175
    },
    {
      "epoch": 1.592920353982301,
      "grad_norm": 8.153177261352539,
      "learning_rate": 4.680432645034415e-05,
      "loss": 1.611,
      "step": 180
    },
    {
      "epoch": 1.6371681415929205,
      "grad_norm": 4.0298895835876465,
      "learning_rate": 4.655850540806293e-05,
      "loss": 1.418,
      "step": 185
    },
    {
      "epoch": 1.6814159292035398,
      "grad_norm": 7.784029960632324,
      "learning_rate": 4.631268436578171e-05,
      "loss": 1.5424,
      "step": 190
    },
    {
      "epoch": 1.7256637168141593,
      "grad_norm": 9.599326133728027,
      "learning_rate": 4.606686332350049e-05,
      "loss": 1.4437,
      "step": 195
    },
    {
      "epoch": 1.7699115044247788,
      "grad_norm": 9.365976333618164,
      "learning_rate": 4.582104228121927e-05,
      "loss": 1.5361,
      "step": 200
    },
    {
      "epoch": 1.8141592920353982,
      "grad_norm": 6.198974609375,
      "learning_rate": 4.5575221238938055e-05,
      "loss": 1.2638,
      "step": 205
    },
    {
      "epoch": 1.8584070796460177,
      "grad_norm": 4.184780120849609,
      "learning_rate": 4.532940019665683e-05,
      "loss": 1.4955,
      "step": 210
    },
    {
      "epoch": 1.9026548672566372,
      "grad_norm": 10.025980949401855,
      "learning_rate": 4.5083579154375616e-05,
      "loss": 1.2571,
      "step": 215
    },
    {
      "epoch": 1.9469026548672566,
      "grad_norm": 6.71586275100708,
      "learning_rate": 4.48377581120944e-05,
      "loss": 1.2893,
      "step": 220
    },
    {
      "epoch": 1.991150442477876,
      "grad_norm": 9.227563858032227,
      "learning_rate": 4.459193706981318e-05,
      "loss": 1.1765,
      "step": 225
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.62,
      "eval_loss": 1.2531030178070068,
      "eval_runtime": 50.6925,
      "eval_samples_per_second": 1.973,
      "eval_steps_per_second": 0.256,
      "step": 226
    },
    {
      "epoch": 2.0353982300884956,
      "grad_norm": 4.875068664550781,
      "learning_rate": 4.434611602753196e-05,
      "loss": 1.2993,
      "step": 230
    },
    {
      "epoch": 2.079646017699115,
      "grad_norm": 5.798208236694336,
      "learning_rate": 4.410029498525074e-05,
      "loss": 1.312,
      "step": 235
    },
    {
      "epoch": 2.1238938053097347,
      "grad_norm": 8.63651180267334,
      "learning_rate": 4.385447394296952e-05,
      "loss": 1.4381,
      "step": 240
    },
    {
      "epoch": 2.168141592920354,
      "grad_norm": 5.678861618041992,
      "learning_rate": 4.36086529006883e-05,
      "loss": 1.2974,
      "step": 245
    },
    {
      "epoch": 2.2123893805309733,
      "grad_norm": 5.9587788581848145,
      "learning_rate": 4.3362831858407084e-05,
      "loss": 1.1695,
      "step": 250
    },
    {
      "epoch": 2.256637168141593,
      "grad_norm": 6.195767402648926,
      "learning_rate": 4.311701081612586e-05,
      "loss": 1.1527,
      "step": 255
    },
    {
      "epoch": 2.3008849557522124,
      "grad_norm": 9.713708877563477,
      "learning_rate": 4.2871189773844646e-05,
      "loss": 1.3234,
      "step": 260
    },
    {
      "epoch": 2.3451327433628317,
      "grad_norm": 7.553620338439941,
      "learning_rate": 4.262536873156342e-05,
      "loss": 1.1209,
      "step": 265
    },
    {
      "epoch": 2.3893805309734515,
      "grad_norm": 4.688574314117432,
      "learning_rate": 4.237954768928221e-05,
      "loss": 1.1788,
      "step": 270
    },
    {
      "epoch": 2.433628318584071,
      "grad_norm": 9.779623031616211,
      "learning_rate": 4.2133726647000984e-05,
      "loss": 1.0553,
      "step": 275
    },
    {
      "epoch": 2.47787610619469,
      "grad_norm": 5.321898460388184,
      "learning_rate": 4.188790560471977e-05,
      "loss": 0.9226,
      "step": 280
    },
    {
      "epoch": 2.52212389380531,
      "grad_norm": 4.392999649047852,
      "learning_rate": 4.164208456243855e-05,
      "loss": 1.1228,
      "step": 285
    },
    {
      "epoch": 2.566371681415929,
      "grad_norm": 5.049253940582275,
      "learning_rate": 4.139626352015733e-05,
      "loss": 1.1372,
      "step": 290
    },
    {
      "epoch": 2.6106194690265485,
      "grad_norm": 6.252779006958008,
      "learning_rate": 4.115044247787611e-05,
      "loss": 0.9933,
      "step": 295
    },
    {
      "epoch": 2.6548672566371683,
      "grad_norm": 10.6918363571167,
      "learning_rate": 4.0904621435594884e-05,
      "loss": 1.1641,
      "step": 300
    },
    {
      "epoch": 2.6991150442477876,
      "grad_norm": 7.936462879180908,
      "learning_rate": 4.065880039331367e-05,
      "loss": 0.9378,
      "step": 305
    },
    {
      "epoch": 2.7433628318584073,
      "grad_norm": 5.671922206878662,
      "learning_rate": 4.0412979351032446e-05,
      "loss": 0.9271,
      "step": 310
    },
    {
      "epoch": 2.7876106194690267,
      "grad_norm": 5.7959675788879395,
      "learning_rate": 4.016715830875123e-05,
      "loss": 1.2543,
      "step": 315
    },
    {
      "epoch": 2.831858407079646,
      "grad_norm": 13.91189956665039,
      "learning_rate": 3.992133726647001e-05,
      "loss": 1.0068,
      "step": 320
    },
    {
      "epoch": 2.8761061946902657,
      "grad_norm": 7.250520706176758,
      "learning_rate": 3.967551622418879e-05,
      "loss": 0.9183,
      "step": 325
    },
    {
      "epoch": 2.920353982300885,
      "grad_norm": 8.308931350708008,
      "learning_rate": 3.9429695181907575e-05,
      "loss": 0.7618,
      "step": 330
    },
    {
      "epoch": 2.9646017699115044,
      "grad_norm": 8.19832706451416,
      "learning_rate": 3.918387413962635e-05,
      "loss": 1.0924,
      "step": 335
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.71,
      "eval_loss": 0.9839953780174255,
      "eval_runtime": 50.3217,
      "eval_samples_per_second": 1.987,
      "eval_steps_per_second": 0.258,
      "step": 339
    },
    {
      "epoch": 3.0088495575221237,
      "grad_norm": 5.136342525482178,
      "learning_rate": 3.893805309734514e-05,
      "loss": 0.7906,
      "step": 340
    },
    {
      "epoch": 3.0530973451327434,
      "grad_norm": 15.530875205993652,
      "learning_rate": 3.8692232055063914e-05,
      "loss": 1.0098,
      "step": 345
    },
    {
      "epoch": 3.0973451327433628,
      "grad_norm": 6.129573345184326,
      "learning_rate": 3.84464110127827e-05,
      "loss": 0.8756,
      "step": 350
    },
    {
      "epoch": 3.1415929203539825,
      "grad_norm": 4.0842814445495605,
      "learning_rate": 3.824975417895772e-05,
      "loss": 0.9317,
      "step": 355
    },
    {
      "epoch": 3.185840707964602,
      "grad_norm": 14.768716812133789,
      "learning_rate": 3.80039331366765e-05,
      "loss": 0.8953,
      "step": 360
    },
    {
      "epoch": 3.230088495575221,
      "grad_norm": 5.315998554229736,
      "learning_rate": 3.780727630285152e-05,
      "loss": 0.9002,
      "step": 365
    },
    {
      "epoch": 3.274336283185841,
      "grad_norm": 4.804921627044678,
      "learning_rate": 3.7561455260570306e-05,
      "loss": 0.7245,
      "step": 370
    },
    {
      "epoch": 3.3185840707964602,
      "grad_norm": 9.81672477722168,
      "learning_rate": 3.731563421828908e-05,
      "loss": 0.7771,
      "step": 375
    },
    {
      "epoch": 3.3628318584070795,
      "grad_norm": 9.358044624328613,
      "learning_rate": 3.706981317600787e-05,
      "loss": 0.6665,
      "step": 380
    },
    {
      "epoch": 3.4070796460176993,
      "grad_norm": 6.652678489685059,
      "learning_rate": 3.682399213372665e-05,
      "loss": 0.7365,
      "step": 385
    },
    {
      "epoch": 3.4513274336283186,
      "grad_norm": 6.04418420791626,
      "learning_rate": 3.657817109144543e-05,
      "loss": 0.7001,
      "step": 390
    },
    {
      "epoch": 3.495575221238938,
      "grad_norm": 4.739931583404541,
      "learning_rate": 3.633235004916421e-05,
      "loss": 1.0258,
      "step": 395
    },
    {
      "epoch": 3.5398230088495577,
      "grad_norm": 7.73756742477417,
      "learning_rate": 3.608652900688299e-05,
      "loss": 0.711,
      "step": 400
    },
    {
      "epoch": 3.584070796460177,
      "grad_norm": 9.829774856567383,
      "learning_rate": 3.5840707964601774e-05,
      "loss": 0.7731,
      "step": 405
    },
    {
      "epoch": 3.6283185840707963,
      "grad_norm": 19.575977325439453,
      "learning_rate": 3.559488692232055e-05,
      "loss": 1.1157,
      "step": 410
    },
    {
      "epoch": 3.672566371681416,
      "grad_norm": 7.629451751708984,
      "learning_rate": 3.5349065880039335e-05,
      "loss": 0.7665,
      "step": 415
    },
    {
      "epoch": 3.7168141592920354,
      "grad_norm": 11.067408561706543,
      "learning_rate": 3.510324483775811e-05,
      "loss": 0.6592,
      "step": 420
    },
    {
      "epoch": 3.7610619469026547,
      "grad_norm": 4.472103595733643,
      "learning_rate": 3.48574237954769e-05,
      "loss": 0.6433,
      "step": 425
    },
    {
      "epoch": 3.8053097345132745,
      "grad_norm": 10.335792541503906,
      "learning_rate": 3.4611602753195674e-05,
      "loss": 0.7732,
      "step": 430
    },
    {
      "epoch": 3.849557522123894,
      "grad_norm": 7.385894298553467,
      "learning_rate": 3.436578171091446e-05,
      "loss": 0.8014,
      "step": 435
    },
    {
      "epoch": 3.893805309734513,
      "grad_norm": 9.80019474029541,
      "learning_rate": 3.4119960668633235e-05,
      "loss": 0.7892,
      "step": 440
    },
    {
      "epoch": 3.938053097345133,
      "grad_norm": 4.320634365081787,
      "learning_rate": 3.387413962635202e-05,
      "loss": 0.6726,
      "step": 445
    },
    {
      "epoch": 3.982300884955752,
      "grad_norm": 8.53462028503418,
      "learning_rate": 3.3628318584070804e-05,
      "loss": 0.6186,
      "step": 450
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.74,
      "eval_loss": 0.7672693133354187,
      "eval_runtime": 50.2824,
      "eval_samples_per_second": 1.989,
      "eval_steps_per_second": 0.259,
      "step": 452
    },
    {
      "epoch": 4.0265486725663715,
      "grad_norm": 11.007576942443848,
      "learning_rate": 3.338249754178958e-05,
      "loss": 0.5737,
      "step": 455
    },
    {
      "epoch": 4.070796460176991,
      "grad_norm": 3.0096468925476074,
      "learning_rate": 3.313667649950836e-05,
      "loss": 0.493,
      "step": 460
    },
    {
      "epoch": 4.115044247787611,
      "grad_norm": 4.964547634124756,
      "learning_rate": 3.2890855457227135e-05,
      "loss": 0.6453,
      "step": 465
    },
    {
      "epoch": 4.15929203539823,
      "grad_norm": 10.605953216552734,
      "learning_rate": 3.264503441494592e-05,
      "loss": 0.6611,
      "step": 470
    },
    {
      "epoch": 4.20353982300885,
      "grad_norm": 10.246184349060059,
      "learning_rate": 3.23992133726647e-05,
      "loss": 0.56,
      "step": 475
    },
    {
      "epoch": 4.247787610619469,
      "grad_norm": 4.128788471221924,
      "learning_rate": 3.215339233038348e-05,
      "loss": 0.547,
      "step": 480
    },
    {
      "epoch": 4.292035398230088,
      "grad_norm": 10.329599380493164,
      "learning_rate": 3.190757128810226e-05,
      "loss": 0.5444,
      "step": 485
    },
    {
      "epoch": 4.336283185840708,
      "grad_norm": 5.2695159912109375,
      "learning_rate": 3.166175024582104e-05,
      "loss": 0.3579,
      "step": 490
    },
    {
      "epoch": 4.380530973451328,
      "grad_norm": 12.777411460876465,
      "learning_rate": 3.1415929203539826e-05,
      "loss": 0.6477,
      "step": 495
    },
    {
      "epoch": 4.424778761061947,
      "grad_norm": 6.543851375579834,
      "learning_rate": 3.1170108161258604e-05,
      "loss": 0.6242,
      "step": 500
    },
    {
      "epoch": 4.469026548672566,
      "grad_norm": 4.0444560050964355,
      "learning_rate": 3.092428711897739e-05,
      "loss": 0.4951,
      "step": 505
    },
    {
      "epoch": 4.513274336283186,
      "grad_norm": 8.856952667236328,
      "learning_rate": 3.0678466076696165e-05,
      "loss": 0.7383,
      "step": 510
    },
    {
      "epoch": 4.557522123893805,
      "grad_norm": 14.531089782714844,
      "learning_rate": 3.0432645034414946e-05,
      "loss": 0.5557,
      "step": 515
    },
    {
      "epoch": 4.601769911504425,
      "grad_norm": 11.453435897827148,
      "learning_rate": 3.018682399213373e-05,
      "loss": 0.6832,
      "step": 520
    },
    {
      "epoch": 4.646017699115045,
      "grad_norm": 2.880875825881958,
      "learning_rate": 2.994100294985251e-05,
      "loss": 0.5857,
      "step": 525
    },
    {
      "epoch": 4.6902654867256635,
      "grad_norm": 6.942078590393066,
      "learning_rate": 2.969518190757129e-05,
      "loss": 0.6936,
      "step": 530
    },
    {
      "epoch": 4.734513274336283,
      "grad_norm": 8.76623249053955,
      "learning_rate": 2.9449360865290072e-05,
      "loss": 0.385,
      "step": 535
    },
    {
      "epoch": 4.778761061946903,
      "grad_norm": 5.114784240722656,
      "learning_rate": 2.9203539823008852e-05,
      "loss": 0.8363,
      "step": 540
    },
    {
      "epoch": 4.823008849557522,
      "grad_norm": 18.143770217895508,
      "learning_rate": 2.8957718780727633e-05,
      "loss": 0.4857,
      "step": 545
    },
    {
      "epoch": 4.867256637168142,
      "grad_norm": 6.451159477233887,
      "learning_rate": 2.8711897738446414e-05,
      "loss": 0.9537,
      "step": 550
    },
    {
      "epoch": 4.911504424778761,
      "grad_norm": 8.477194786071777,
      "learning_rate": 2.8466076696165195e-05,
      "loss": 0.5073,
      "step": 555
    },
    {
      "epoch": 4.95575221238938,
      "grad_norm": 5.607450008392334,
      "learning_rate": 2.8220255653883975e-05,
      "loss": 0.4709,
      "step": 560
    },
    {
      "epoch": 5.0,
      "grad_norm": 24.763206481933594,
      "learning_rate": 2.7974434611602756e-05,
      "loss": 0.5407,
      "step": 565
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.82,
      "eval_loss": 0.6962552070617676,
      "eval_runtime": 49.9129,
      "eval_samples_per_second": 2.003,
      "eval_steps_per_second": 0.26,
      "step": 565
    }
  ],
  "logging_steps": 5,
  "max_steps": 1130,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.066994137312e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
