{
  "best_global_step": 339,
  "best_metric": 0.71,
  "best_model_checkpoint": "distilhubert-finetuned-gtzan/checkpoint-339",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 339,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04424778761061947,
      "grad_norm": 1.1449623107910156,
      "learning_rate": 1.7699115044247788e-06,
      "loss": 2.2861,
      "step": 5
    },
    {
      "epoch": 0.08849557522123894,
      "grad_norm": 1.6510204076766968,
      "learning_rate": 3.982300884955752e-06,
      "loss": 2.289,
      "step": 10
    },
    {
      "epoch": 0.13274336283185842,
      "grad_norm": 1.1722270250320435,
      "learning_rate": 6.194690265486726e-06,
      "loss": 2.2741,
      "step": 15
    },
    {
      "epoch": 0.17699115044247787,
      "grad_norm": 1.4926832914352417,
      "learning_rate": 8.407079646017701e-06,
      "loss": 2.2966,
      "step": 20
    },
    {
      "epoch": 0.22123893805309736,
      "grad_norm": 1.5397741794586182,
      "learning_rate": 1.0619469026548673e-05,
      "loss": 2.2728,
      "step": 25
    },
    {
      "epoch": 0.26548672566371684,
      "grad_norm": 1.9833863973617554,
      "learning_rate": 1.2831858407079647e-05,
      "loss": 2.2914,
      "step": 30
    },
    {
      "epoch": 0.30973451327433627,
      "grad_norm": 1.2983826398849487,
      "learning_rate": 1.504424778761062e-05,
      "loss": 2.2535,
      "step": 35
    },
    {
      "epoch": 0.35398230088495575,
      "grad_norm": 1.8112915754318237,
      "learning_rate": 1.7256637168141594e-05,
      "loss": 2.2537,
      "step": 40
    },
    {
      "epoch": 0.39823008849557523,
      "grad_norm": 1.2817487716674805,
      "learning_rate": 1.946902654867257e-05,
      "loss": 2.2791,
      "step": 45
    },
    {
      "epoch": 0.4424778761061947,
      "grad_norm": 1.5343743562698364,
      "learning_rate": 2.1681415929203542e-05,
      "loss": 2.2788,
      "step": 50
    },
    {
      "epoch": 0.48672566371681414,
      "grad_norm": 1.6184659004211426,
      "learning_rate": 2.3893805309734516e-05,
      "loss": 2.2208,
      "step": 55
    },
    {
      "epoch": 0.5309734513274337,
      "grad_norm": 1.6852747201919556,
      "learning_rate": 2.610619469026549e-05,
      "loss": 2.2329,
      "step": 60
    },
    {
      "epoch": 0.5752212389380531,
      "grad_norm": 1.7722140550613403,
      "learning_rate": 2.831858407079646e-05,
      "loss": 2.2293,
      "step": 65
    },
    {
      "epoch": 0.6194690265486725,
      "grad_norm": 1.9347562789916992,
      "learning_rate": 3.0530973451327434e-05,
      "loss": 2.1866,
      "step": 70
    },
    {
      "epoch": 0.6637168141592921,
      "grad_norm": 1.8920925855636597,
      "learning_rate": 3.274336283185841e-05,
      "loss": 2.149,
      "step": 75
    },
    {
      "epoch": 0.7079646017699115,
      "grad_norm": 2.1080193519592285,
      "learning_rate": 3.495575221238938e-05,
      "loss": 2.1437,
      "step": 80
    },
    {
      "epoch": 0.7522123893805309,
      "grad_norm": 3.8945271968841553,
      "learning_rate": 3.716814159292036e-05,
      "loss": 2.0822,
      "step": 85
    },
    {
      "epoch": 0.7964601769911505,
      "grad_norm": 1.6137644052505493,
      "learning_rate": 3.938053097345133e-05,
      "loss": 2.0252,
      "step": 90
    },
    {
      "epoch": 0.8407079646017699,
      "grad_norm": 4.367221355438232,
      "learning_rate": 4.15929203539823e-05,
      "loss": 2.069,
      "step": 95
    },
    {
      "epoch": 0.8849557522123894,
      "grad_norm": 3.666867256164551,
      "learning_rate": 4.380530973451328e-05,
      "loss": 2.0042,
      "step": 100
    },
    {
      "epoch": 0.9292035398230089,
      "grad_norm": 4.560084342956543,
      "learning_rate": 4.601769911504425e-05,
      "loss": 2.0425,
      "step": 105
    },
    {
      "epoch": 0.9734513274336283,
      "grad_norm": 4.888540744781494,
      "learning_rate": 4.823008849557522e-05,
      "loss": 1.9087,
      "step": 110
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.5,
      "eval_loss": 1.83154296875,
      "eval_runtime": 53.6867,
      "eval_samples_per_second": 1.863,
      "eval_steps_per_second": 0.242,
      "step": 113
    },
    {
      "epoch": 1.0176991150442478,
      "grad_norm": 6.26556921005249,
      "learning_rate": 4.9950835791543757e-05,
      "loss": 1.9371,
      "step": 115
    },
    {
      "epoch": 1.0619469026548674,
      "grad_norm": 3.2880985736846924,
      "learning_rate": 4.970501474926254e-05,
      "loss": 1.8339,
      "step": 120
    },
    {
      "epoch": 1.1061946902654867,
      "grad_norm": 4.991643905639648,
      "learning_rate": 4.9459193706981325e-05,
      "loss": 1.7344,
      "step": 125
    },
    {
      "epoch": 1.1504424778761062,
      "grad_norm": 4.315277099609375,
      "learning_rate": 4.92133726647001e-05,
      "loss": 1.6742,
      "step": 130
    },
    {
      "epoch": 1.1946902654867257,
      "grad_norm": 4.716861724853516,
      "learning_rate": 4.9016715830875125e-05,
      "loss": 1.6835,
      "step": 135
    },
    {
      "epoch": 1.238938053097345,
      "grad_norm": 5.1262102127075195,
      "learning_rate": 4.877089478859391e-05,
      "loss": 1.7226,
      "step": 140
    },
    {
      "epoch": 1.2831858407079646,
      "grad_norm": 3.7036373615264893,
      "learning_rate": 4.8525073746312687e-05,
      "loss": 1.6258,
      "step": 145
    },
    {
      "epoch": 1.3274336283185841,
      "grad_norm": 3.9151556491851807,
      "learning_rate": 4.827925270403147e-05,
      "loss": 1.6485,
      "step": 150
    },
    {
      "epoch": 1.3716814159292037,
      "grad_norm": 9.768646240234375,
      "learning_rate": 4.803343166175025e-05,
      "loss": 1.5928,
      "step": 155
    },
    {
      "epoch": 1.415929203539823,
      "grad_norm": 4.900234222412109,
      "learning_rate": 4.778761061946903e-05,
      "loss": 1.6012,
      "step": 160
    },
    {
      "epoch": 1.4601769911504425,
      "grad_norm": 4.511559009552002,
      "learning_rate": 4.754178957718781e-05,
      "loss": 1.475,
      "step": 165
    },
    {
      "epoch": 1.504424778761062,
      "grad_norm": 6.970420837402344,
      "learning_rate": 4.729596853490659e-05,
      "loss": 1.4712,
      "step": 170
    },
    {
      "epoch": 1.5486725663716814,
      "grad_norm": 8.933089256286621,
      "learning_rate": 4.705014749262537e-05,
      "loss": 1.476,
      "step": 175
    },
    {
      "epoch": 1.592920353982301,
      "grad_norm": 8.153177261352539,
      "learning_rate": 4.680432645034415e-05,
      "loss": 1.611,
      "step": 180
    },
    {
      "epoch": 1.6371681415929205,
      "grad_norm": 4.0298895835876465,
      "learning_rate": 4.655850540806293e-05,
      "loss": 1.418,
      "step": 185
    },
    {
      "epoch": 1.6814159292035398,
      "grad_norm": 7.784029960632324,
      "learning_rate": 4.631268436578171e-05,
      "loss": 1.5424,
      "step": 190
    },
    {
      "epoch": 1.7256637168141593,
      "grad_norm": 9.599326133728027,
      "learning_rate": 4.606686332350049e-05,
      "loss": 1.4437,
      "step": 195
    },
    {
      "epoch": 1.7699115044247788,
      "grad_norm": 9.365976333618164,
      "learning_rate": 4.582104228121927e-05,
      "loss": 1.5361,
      "step": 200
    },
    {
      "epoch": 1.8141592920353982,
      "grad_norm": 6.198974609375,
      "learning_rate": 4.5575221238938055e-05,
      "loss": 1.2638,
      "step": 205
    },
    {
      "epoch": 1.8584070796460177,
      "grad_norm": 4.184780120849609,
      "learning_rate": 4.532940019665683e-05,
      "loss": 1.4955,
      "step": 210
    },
    {
      "epoch": 1.9026548672566372,
      "grad_norm": 10.025980949401855,
      "learning_rate": 4.5083579154375616e-05,
      "loss": 1.2571,
      "step": 215
    },
    {
      "epoch": 1.9469026548672566,
      "grad_norm": 6.71586275100708,
      "learning_rate": 4.48377581120944e-05,
      "loss": 1.2893,
      "step": 220
    },
    {
      "epoch": 1.991150442477876,
      "grad_norm": 9.227563858032227,
      "learning_rate": 4.459193706981318e-05,
      "loss": 1.1765,
      "step": 225
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.62,
      "eval_loss": 1.2531030178070068,
      "eval_runtime": 50.6925,
      "eval_samples_per_second": 1.973,
      "eval_steps_per_second": 0.256,
      "step": 226
    },
    {
      "epoch": 2.0353982300884956,
      "grad_norm": 4.875068664550781,
      "learning_rate": 4.434611602753196e-05,
      "loss": 1.2993,
      "step": 230
    },
    {
      "epoch": 2.079646017699115,
      "grad_norm": 5.798208236694336,
      "learning_rate": 4.410029498525074e-05,
      "loss": 1.312,
      "step": 235
    },
    {
      "epoch": 2.1238938053097347,
      "grad_norm": 8.63651180267334,
      "learning_rate": 4.385447394296952e-05,
      "loss": 1.4381,
      "step": 240
    },
    {
      "epoch": 2.168141592920354,
      "grad_norm": 5.678861618041992,
      "learning_rate": 4.36086529006883e-05,
      "loss": 1.2974,
      "step": 245
    },
    {
      "epoch": 2.2123893805309733,
      "grad_norm": 5.9587788581848145,
      "learning_rate": 4.3362831858407084e-05,
      "loss": 1.1695,
      "step": 250
    },
    {
      "epoch": 2.256637168141593,
      "grad_norm": 6.195767402648926,
      "learning_rate": 4.311701081612586e-05,
      "loss": 1.1527,
      "step": 255
    },
    {
      "epoch": 2.3008849557522124,
      "grad_norm": 9.713708877563477,
      "learning_rate": 4.2871189773844646e-05,
      "loss": 1.3234,
      "step": 260
    },
    {
      "epoch": 2.3451327433628317,
      "grad_norm": 7.553620338439941,
      "learning_rate": 4.262536873156342e-05,
      "loss": 1.1209,
      "step": 265
    },
    {
      "epoch": 2.3893805309734515,
      "grad_norm": 4.688574314117432,
      "learning_rate": 4.237954768928221e-05,
      "loss": 1.1788,
      "step": 270
    },
    {
      "epoch": 2.433628318584071,
      "grad_norm": 9.779623031616211,
      "learning_rate": 4.2133726647000984e-05,
      "loss": 1.0553,
      "step": 275
    },
    {
      "epoch": 2.47787610619469,
      "grad_norm": 5.321898460388184,
      "learning_rate": 4.188790560471977e-05,
      "loss": 0.9226,
      "step": 280
    },
    {
      "epoch": 2.52212389380531,
      "grad_norm": 4.392999649047852,
      "learning_rate": 4.164208456243855e-05,
      "loss": 1.1228,
      "step": 285
    },
    {
      "epoch": 2.566371681415929,
      "grad_norm": 5.049253940582275,
      "learning_rate": 4.139626352015733e-05,
      "loss": 1.1372,
      "step": 290
    },
    {
      "epoch": 2.6106194690265485,
      "grad_norm": 6.252779006958008,
      "learning_rate": 4.115044247787611e-05,
      "loss": 0.9933,
      "step": 295
    },
    {
      "epoch": 2.6548672566371683,
      "grad_norm": 10.6918363571167,
      "learning_rate": 4.0904621435594884e-05,
      "loss": 1.1641,
      "step": 300
    },
    {
      "epoch": 2.6991150442477876,
      "grad_norm": 7.936462879180908,
      "learning_rate": 4.065880039331367e-05,
      "loss": 0.9378,
      "step": 305
    },
    {
      "epoch": 2.7433628318584073,
      "grad_norm": 5.671922206878662,
      "learning_rate": 4.0412979351032446e-05,
      "loss": 0.9271,
      "step": 310
    },
    {
      "epoch": 2.7876106194690267,
      "grad_norm": 5.7959675788879395,
      "learning_rate": 4.016715830875123e-05,
      "loss": 1.2543,
      "step": 315
    },
    {
      "epoch": 2.831858407079646,
      "grad_norm": 13.91189956665039,
      "learning_rate": 3.992133726647001e-05,
      "loss": 1.0068,
      "step": 320
    },
    {
      "epoch": 2.8761061946902657,
      "grad_norm": 7.250520706176758,
      "learning_rate": 3.967551622418879e-05,
      "loss": 0.9183,
      "step": 325
    },
    {
      "epoch": 2.920353982300885,
      "grad_norm": 8.308931350708008,
      "learning_rate": 3.9429695181907575e-05,
      "loss": 0.7618,
      "step": 330
    },
    {
      "epoch": 2.9646017699115044,
      "grad_norm": 8.19832706451416,
      "learning_rate": 3.918387413962635e-05,
      "loss": 1.0924,
      "step": 335
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.71,
      "eval_loss": 0.9839953780174255,
      "eval_runtime": 50.3217,
      "eval_samples_per_second": 1.987,
      "eval_steps_per_second": 0.258,
      "step": 339
    }
  ],
  "logging_steps": 5,
  "max_steps": 1130,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.8401964823872e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
